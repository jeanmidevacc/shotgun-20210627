{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3_hyperopt\n",
    "\n",
    "A notebook to set a research of hyperparamter based on hyperopt libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from hyperopt import fmin, tpe, hp, anneal, Trials\n",
    "\n",
    "import wandb\n",
    "import pickle\n",
    "\n",
    "evaluation_metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_train = pd.read_csv('./data/rtu/model_train_data.csv')\n",
    "dfp_train['date'] = pd.to_datetime(dfp_train['date'])\n",
    "\n",
    "dfp_test = pd.read_csv('./data/rtu/model_test_data.csv')\n",
    "dfp_test['date'] = pd.to_datetime(dfp_test['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_weather = [ 't2m_min_bordeaux',\n",
    "       't2m_bordeaux', 't2m_max_bordeaux', 'prectot_bordeaux', 't2m_min_lille',\n",
    "       't2m_lille', 't2m_max_lille', 'prectot_lille', 't2m_min_paris',\n",
    "       't2m_paris', 't2m_max_paris', 'prectot_paris', 't2m_min_rennes',\n",
    "       't2m_rennes', 't2m_max_rennes', 'prectot_rennes', 't2m_min_nantes',\n",
    "       't2m_nantes', 't2m_max_nantes', 'prectot_nantes', 't2m_min_toulouse',\n",
    "       't2m_toulouse', 't2m_max_toulouse', 'prectot_toulouse',\n",
    "       't2m_min_marseille', 't2m_marseille', 't2m_max_marseille',\n",
    "       'prectot_marseille', 't2m_min_lyon', 't2m_lyon', 't2m_max_lyon',\n",
    "       'prectot_lyon', 't2m_min_nice', 't2m_nice', 't2m_max_nice',\n",
    "       'prectot_nice', 't2m_min_strasbourg', 't2m_strasbourg',\n",
    "       't2m_max_strasbourg', 'prectot_strasbourg', 't2m_min_montpellier',\n",
    "       't2m_montpellier', 't2m_max_montpellier', 'prectot_montpellier',\n",
    "       'weighted_t2m', 'weighted_t2m_min', 'weighted_t2m_max',\n",
    "       'weighted_prectot']\n",
    "\n",
    "columns_features = ['weekday', 'month', 'week_number'] + columns_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_target = 'daily_electrical_consumption'\n",
    "X_train, y_train = dfp_train[columns_features], dfp_train[column_target]\n",
    "X_test, y_test = dfp_test[columns_features], dfp_test[column_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(params, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test):\n",
    "    # the function gets a set of variable parameters in \"param\"\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        'criterion' : params['criterion'],\n",
    "        'max_depth' : params['max_depth'],\n",
    "        'min_samples_split' : params['min_samples_split'],\n",
    "        'max_features' : params['max_features']\n",
    "    }\n",
    "    \n",
    "    # we use this params to create a new LGBM Regressor\n",
    "    model = RandomForestRegressor( **params)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "    return rmse\n",
    "\n",
    "# Space definition\n",
    "space={\n",
    "    'n_estimators': hp.quniform('n_estimators', 2, 100, 1),\n",
    "    'criterion' : hp.choice('criterion', ['mse', 'mae']),\n",
    "    'max_depth' : hp.quniform('max_depth', 2, 100, 1),\n",
    "    'min_samples_split' : hp.quniform('min_samples_split', 0.1, 1, 0.1),\n",
    "    'max_features' : hp.choice('max_features', ['auto', 'sqrt', 'log2']),\n",
    "}\n",
    "\n",
    "# Trigger the search\n",
    "trials = Trials()\n",
    "best=fmin(fn=train_and_evaluate, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          max_evals=10, # maximum number of iterations\n",
    "          trials=trials, # logging\n",
    "          rstate=np.random.RandomState(0) # fixing random state for the reproducibility\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train hte model with the best parameters\n",
    "params = {\n",
    "    'n_estimators': int(best['n_estimators']),\n",
    "    'criterion' : ['mse', 'mae'][best['criterion']],\n",
    "    'max_depth' : int(best['max_depth']),\n",
    "    'min_samples_split' : best['min_samples_split'],\n",
    "    'max_features' : ['auto', 'sqrt', 'log2'][best['max_features']]\n",
    "}\n",
    "\n",
    "# we use this params to create a new LGBM Regressor\n",
    "model = RandomForestRegressor( **params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build some metrics\n",
    "wandb.init(project='french_electrical_consumption', entity='jmdaignan')\n",
    "wandb.sklearn.plot_regressor(model, X_train, X_test, y_train, y_test,  model_name='best_hyperopt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:23ogw36v) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6082<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/jmdaignan/Development/shotgun-20210627/wandb/run-20210627_091613-23ogw36v/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/jmdaignan/Development/shotgun-20210627/wandb/run-20210627_091613-23ogw36v/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">pretty-totem-345</strong>: <a href=\"https://wandb.ai/jmdaignan/french_electrical_consumption/runs/23ogw36v\" target=\"_blank\">https://wandb.ai/jmdaignan/french_electrical_consumption/runs/23ogw36v</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:23ogw36v). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.32 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.31<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">stilted-snowflake-353</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jmdaignan/french_electrical_consumption\" target=\"_blank\">https://wandb.ai/jmdaignan/french_electrical_consumption</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jmdaignan/french_electrical_consumption/runs/fj31qhra\" target=\"_blank\">https://wandb.ai/jmdaignan/french_electrical_consumption/runs/fj31qhra</a><br/>\n",
       "                Run data is saved locally in <code>/home/jmdaignan/Development/shotgun-20210627/wandb/run-20210627_093736-fj31qhra</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x7f2ed27e0d50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "run = wandb.init(project='french_electrical_consumption', entity='jmdaignan')\n",
    "\n",
    "trained_model_artifact = wandb.Artifact('best_model_hyperopt', type='model', description='Best model from the hyperopt')\n",
    "\n",
    "file_model = './data/model.pkl'\n",
    "with open(file_model, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "trained_model_artifact.add_file(file_model)\n",
    "\n",
    "run.log_artifact(trained_model_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oldml_p37",
   "language": "python",
   "name": "oldml_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
