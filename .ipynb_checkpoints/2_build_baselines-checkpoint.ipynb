{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "from supervised.automl import AutoML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import wandb\n",
    "\n",
    "evaluation_metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_train = pd.read_csv('./data/rtu/model_train_data.csv')\n",
    "dfp_train['date'] = pd.to_datetime(dfp_train['date'])\n",
    "\n",
    "dfp_test = pd.read_csv('./data/rtu/model_test_data.csv')\n",
    "dfp_test['date'] = pd.to_datetime(dfp_test['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_weather = [ 't2m_min_bordeaux',\n",
    "       't2m_bordeaux', 't2m_max_bordeaux', 'prectot_bordeaux', 't2m_min_lille',\n",
    "       't2m_lille', 't2m_max_lille', 'prectot_lille', 't2m_min_paris',\n",
    "       't2m_paris', 't2m_max_paris', 'prectot_paris', 't2m_min_rennes',\n",
    "       't2m_rennes', 't2m_max_rennes', 'prectot_rennes', 't2m_min_nantes',\n",
    "       't2m_nantes', 't2m_max_nantes', 'prectot_nantes', 't2m_min_toulouse',\n",
    "       't2m_toulouse', 't2m_max_toulouse', 'prectot_toulouse',\n",
    "       't2m_min_marseille', 't2m_marseille', 't2m_max_marseille',\n",
    "       'prectot_marseille', 't2m_min_lyon', 't2m_lyon', 't2m_max_lyon',\n",
    "       'prectot_lyon', 't2m_min_nice', 't2m_nice', 't2m_max_nice',\n",
    "       'prectot_nice', 't2m_min_strasbourg', 't2m_strasbourg',\n",
    "       't2m_max_strasbourg', 'prectot_strasbourg', 't2m_min_montpellier',\n",
    "       't2m_montpellier', 't2m_max_montpellier', 'prectot_montpellier',\n",
    "       'weighted_t2m', 'weighted_t2m_min', 'weighted_t2m_max',\n",
    "       'weighted_prectot']\n",
    "\n",
    "columns_features = ['weekday', 'month', 'week_number'] + columns_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep it simple only date and consumption\n",
    "column_target = 'daily_electrical_consumption'\n",
    "X_train, y_train = dfp_train[columns_features], dfp_train[column_target]\n",
    "X_test, y_test = dfp_test[columns_features], dfp_test[column_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the test-set: 985540.6966280716\n"
     ]
    }
   ],
   "source": [
    "# First baseline\n",
    "predictions = [random.randrange(y_train.min(), y_train.max()) for idx in range(len(y_test))]\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "evaluation_metrics.append({'model' : 'random', 'rmse' : rmse})\n",
    "print('RMSE on the test-set:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the test-set: 927086.0371777667\n"
     ]
    }
   ],
   "source": [
    "# Second baseline, still a little bit random but a little bit of knowledge based\n",
    "dfp_tmp = dfp_train.groupby(['month', 'weekday']).agg({column_target : ['min', 'max']})\n",
    "dfp_tmp.columns = ['min', 'max']\n",
    "dfp_tmp.reset_index(inplace=True)\n",
    "\n",
    "dfp_tmp['key'] = dfp_tmp.apply(lambda row: f\"{row['month']}-{row['weekday']}\", axis=1)\n",
    "dfp_tmp.set_index('key', drop=True, inplace=True)\n",
    "\n",
    "dict_knowledge = dfp_tmp[['min', 'max']].to_dict(orient='index')\n",
    "dict_knowledge['x-x'] = {'min' : y_train.min(), 'max' : y_train.max()}\n",
    "\n",
    "def get_randomish_consumption(month, weekday, dict_knowledge):\n",
    "    \n",
    "    key = f\"{month}-{weekday}\"\n",
    "    if key not in dict_knowledge:\n",
    "        key = 'x-x'\n",
    "    return random.randrange(dict_knowledge[key]['min'], dict_knowledge[key]['max'])\n",
    "   \n",
    "predictions = [get_randomish_consumption(row['month'], row['weekday'], dict_knowledge) for idx, row in dfp_test.iterrows()] \n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "evaluation_metrics.append({'model' : 'randomish', 'rmse' : rmse})\n",
    "print('RMSE on the test-set:', rmse)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: AutoML_2\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['Baseline', 'Linear', 'Decision Tree', 'Random Forest', 'Xgboost', 'Neural Network']\n",
      "AutoML will ensemble availabe models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'ensemble']\n",
      "* Step simple_algorithms will try to check up to 3 models\n",
      "1_Baseline rmse 515197.30308 trained in 0.37 seconds\n",
      "2_DecisionTree rmse 433299.458476 trained in 6.84 seconds\n",
      "3_Linear rmse 439952.141777 trained in 2.53 seconds\n",
      "* Step default_algorithms will try to check up to 3 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_Default_Xgboost rmse 405015.521824 trained in 8.0 seconds\n",
      "5_Default_NeuralNetwork rmse 430172.411576 trained in 0.91 seconds\n",
      "6_Default_RandomForest rmse 416696.642759 trained in 6.33 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 402723.43411 trained in 0.23 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An input array is constant; the correlation coefficent is not defined.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML fit time: 40.02 seconds\n",
      "AutoML best model: Ensemble\n",
      "RMSE on the test-set: 425946.06338705606\n",
      "CPU times: user 53.9 s, sys: 946 ms, total: 54.9 s\n",
      "Wall time: 40.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "automl = AutoML() # mode=Explain, Perform, Compete\n",
    "automl.fit(X_train, y_train)\n",
    "predictions = automl.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "evaluation_metrics.append({'model' : 'mljar-bm', 'rmse' : rmse})\n",
    "print('RMSE on the test-set:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the test-set: 473806.71499787306\n"
     ]
    }
   ],
   "source": [
    "def ptg_model(x, a, b, x0):\n",
    "    return np.piecewise(x, [x < x0, x >= x0], [lambda x: a*x+b , lambda x:a*x0+b])\n",
    "\n",
    "def get_model_ptg(x,y):\n",
    "    x0_min = 0\n",
    "    x0_max = 20\n",
    "    a_min=-200000\n",
    "    a_max=-50000\n",
    "    b_min=1000000\n",
    "    b_max=3000000\n",
    "    bounds_min = [a_min, b_min, x0_min]\n",
    "    bounds_max = [a_max, b_max, x0_max]\n",
    "    bounds = (bounds_min, bounds_max)\n",
    "    popt, pcov = scipy.optimize.curve_fit(ptg_model, x, y, bounds=bounds)\n",
    "    a= popt[0]\n",
    "    b = popt[1]\n",
    "    x0 = popt[2]\n",
    "    return a,b,x0\n",
    "\n",
    "a, b, x0 = get_model_ptg(X_train['weighted_t2m'].tolist(),y_train)\n",
    "predictions = [ptg_model(row['weighted_t2m'], a, b, x0) for idx, row in dfp_test.iterrows()] \n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "evaluation_metrics.append({'model' : 'ptg-wt2m', 'rmse' : rmse})\n",
    "print('RMSE on the test-set:', rmse)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the test-set: 463374.5758606644\n"
     ]
    }
   ],
   "source": [
    "a, b, x0 = get_model_ptg(X_train['weighted_t2m_min'].tolist(),y_train)\n",
    "predictions = [ptg_model(row['weighted_t2m_min'], a, b, x0) for idx, row in dfp_test.iterrows()] \n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "evaluation_metrics.append({'model' : 'ptg-wt2mmin', 'rmse' : rmse})\n",
    "print('RMSE on the test-set:', rmse)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_evaluation_metrics = pd.DataFrame(evaluation_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:m29dpwcp) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 21005<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/jmdaignan/Development/shotgun_test_libs/wandb/run-20210622_104919-m29dpwcp/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/jmdaignan/Development/shotgun_test_libs/wandb/run-20210622_104919-m29dpwcp/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>6</td></tr><tr><td>_timestamp</td><td>1624373368</td></tr><tr><td>_step</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">devoted-field-110</strong>: <a href=\"https://wandb.ai/jmdaignan/french_electrical_consumption/runs/m29dpwcp\" target=\"_blank\">https://wandb.ai/jmdaignan/french_electrical_consumption/runs/m29dpwcp</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:m29dpwcp). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.32 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.31<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">major-dawn-111</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jmdaignan/french_electrical_consumption\" target=\"_blank\">https://wandb.ai/jmdaignan/french_electrical_consumption</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jmdaignan/french_electrical_consumption/runs/3d02hkpf\" target=\"_blank\">https://wandb.ai/jmdaignan/french_electrical_consumption/runs/3d02hkpf</a><br/>\n",
       "                Run data is saved locally in <code>/home/jmdaignan/Development/shotgun_test_libs/wandb/run-20210622_134134-3d02hkpf</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:07.916659, resuming normal operation.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:08.098749, resuming normal operation.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:08.191887, resuming normal operation.\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project='french_electrical_consumption', entity='jmdaignan')\n",
    "data = [[row['model'], row['rmse']] for idx, row in dfp_evaluation_metrics.iterrows()]\n",
    "table = wandb.Table(data=data, columns = [\"model\", \"rmse\"])\n",
    "wandb.log({\"comparison_baseline\" : wandb.plot.bar(table, \"model\", \"rmse\", title=\"Comparison baseline models\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oldml_p37",
   "language": "python",
   "name": "oldml_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
