{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2_build_baselines\n",
    "\n",
    "Notebook to build baseline models to iterate on a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "from supervised.automl import AutoML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import wandb\n",
    "\n",
    "evaluation_metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the data\n",
    "dfp_train = pd.read_csv('./data/rtu/model_train_data.csv')\n",
    "dfp_train['date'] = pd.to_datetime(dfp_train['date'])\n",
    "\n",
    "dfp_test = pd.read_csv('./data/rtu/model_test_data.csv')\n",
    "dfp_test['date'] = pd.to_datetime(dfp_test['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defione the columns and features\n",
    "columns_weather = [ 't2m_min_bordeaux',\n",
    "       't2m_bordeaux', 't2m_max_bordeaux', 'prectot_bordeaux', 't2m_min_lille',\n",
    "       't2m_lille', 't2m_max_lille', 'prectot_lille', 't2m_min_paris',\n",
    "       't2m_paris', 't2m_max_paris', 'prectot_paris', 't2m_min_rennes',\n",
    "       't2m_rennes', 't2m_max_rennes', 'prectot_rennes', 't2m_min_nantes',\n",
    "       't2m_nantes', 't2m_max_nantes', 'prectot_nantes', 't2m_min_toulouse',\n",
    "       't2m_toulouse', 't2m_max_toulouse', 'prectot_toulouse',\n",
    "       't2m_min_marseille', 't2m_marseille', 't2m_max_marseille',\n",
    "       'prectot_marseille', 't2m_min_lyon', 't2m_lyon', 't2m_max_lyon',\n",
    "       'prectot_lyon', 't2m_min_nice', 't2m_nice', 't2m_max_nice',\n",
    "       'prectot_nice', 't2m_min_strasbourg', 't2m_strasbourg',\n",
    "       't2m_max_strasbourg', 'prectot_strasbourg', 't2m_min_montpellier',\n",
    "       't2m_montpellier', 't2m_max_montpellier', 'prectot_montpellier',\n",
    "       'weighted_t2m', 'weighted_t2m_min', 'weighted_t2m_max',\n",
    "       'weighted_prectot']\n",
    "\n",
    "columns_features = ['weekday', 'month', 'week_number'] + columns_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_target = 'daily_electrical_consumption'\n",
    "X_train, y_train = dfp_train[columns_features], dfp_train[column_target]\n",
    "X_test, y_test = dfp_test[columns_features], dfp_test[column_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First baseline\n",
    "predictions = [random.randrange(y_train.min(), y_train.max()) for idx in range(len(y_test))]\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "evaluation_metrics.append({'model' : 'random', 'rmse' : rmse})\n",
    "print('RMSE on the test-set:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second baseline, still a little bit random but a little bit of knowledge based\n",
    "dfp_tmp = dfp_train.groupby(['month', 'weekday']).agg({column_target : ['min', 'max']})\n",
    "dfp_tmp.columns = ['min', 'max']\n",
    "dfp_tmp.reset_index(inplace=True)\n",
    "\n",
    "dfp_tmp['key'] = dfp_tmp.apply(lambda row: f\"{row['month']}-{row['weekday']}\", axis=1)\n",
    "dfp_tmp.set_index('key', drop=True, inplace=True)\n",
    "\n",
    "dict_knowledge = dfp_tmp[['min', 'max']].to_dict(orient='index')\n",
    "dict_knowledge['x-x'] = {'min' : y_train.min(), 'max' : y_train.max()}\n",
    "\n",
    "def get_randomish_consumption(month, weekday, dict_knowledge):\n",
    "    \n",
    "    key = f\"{month}-{weekday}\"\n",
    "    if key not in dict_knowledge:\n",
    "        key = 'x-x'\n",
    "    return random.randrange(dict_knowledge[key]['min'], dict_knowledge[key]['max'])\n",
    "   \n",
    "predictions = [get_randomish_consumption(row['month'], row['weekday'], dict_knowledge) for idx, row in dfp_test.iterrows()] \n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "evaluation_metrics.append({'model' : 'randomish', 'rmse' : rmse})\n",
    "print('RMSE on the test-set:', rmse)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "automl = AutoML() # mode=Explain, Perform, Compete\n",
    "automl.fit(X_train, y_train)\n",
    "predictions = automl.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "evaluation_metrics.append({'model' : 'mljar-bm', 'rmse' : rmse})\n",
    "print('RMSE on the test-set:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptg_model(x, a, b, x0):\n",
    "    return np.piecewise(x, [x < x0, x >= x0], [lambda x: a*x+b , lambda x:a*x0+b])\n",
    "\n",
    "def get_model_ptg(x,y):\n",
    "    x0_min = 0\n",
    "    x0_max = 20\n",
    "    a_min=-200000\n",
    "    a_max=-50000\n",
    "    b_min=1000000\n",
    "    b_max=3000000\n",
    "    bounds_min = [a_min, b_min, x0_min]\n",
    "    bounds_max = [a_max, b_max, x0_max]\n",
    "    bounds = (bounds_min, bounds_max)\n",
    "    popt, pcov = scipy.optimize.curve_fit(ptg_model, x, y, bounds=bounds)\n",
    "    a= popt[0]\n",
    "    b = popt[1]\n",
    "    x0 = popt[2]\n",
    "    return a,b,x0\n",
    "\n",
    "a, b, x0 = get_model_ptg(X_train['weighted_t2m'].tolist(),y_train)\n",
    "predictions = [ptg_model(row['weighted_t2m'], a, b, x0) for idx, row in dfp_test.iterrows()] \n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "evaluation_metrics.append({'model' : 'ptg-wt2m', 'rmse' : rmse})\n",
    "print('RMSE on the test-set:', rmse)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, x0 = get_model_ptg(X_train['weighted_t2m_min'].tolist(),y_train)\n",
    "predictions = [ptg_model(row['weighted_t2m_min'], a, b, x0) for idx, row in dfp_test.iterrows()] \n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "evaluation_metrics.append({'model' : 'ptg-wt2mmin', 'rmse' : rmse})\n",
    "print('RMSE on the test-set:', rmse)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, x0 = get_model_ptg(X_train['weighted_t2m_max'].tolist(),y_train)\n",
    "predictions = [ptg_model(row['weighted_t2m_max'], a, b, x0) for idx, row in dfp_test.iterrows()] \n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "evaluation_metrics.append({'model' : 'ptg-wt2mmax', 'rmse' : rmse})\n",
    "print('RMSE on the test-set:', rmse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_evaluation_metrics = pd.DataFrame(evaluation_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the results in wandb\n",
    "wandb.init(project='french_electrical_consumption', entity='jmdaignan')\n",
    "data = [[row['model'], row['rmse']] for idx, row in dfp_evaluation_metrics.iterrows()]\n",
    "table = wandb.Table(data=data, columns = [\"model\", \"rmse\"])\n",
    "wandb.log({\"comparison_baseline\" : wandb.plot.bar(table, \"model\", \"rmse\", title=\"Comparison baseline models\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oldml_p37",
   "language": "python",
   "name": "oldml_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
